#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–åçš„å¸ƒå±€ï¼šçª„ä¿¡æ¯æ  + å¤§PDFé¢„è§ˆ + ä¿®å¤æ–‡å­—é‡å 
"""

import os
import sys
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

def test_optimized_layout():
    """æµ‹è¯•ä¼˜åŒ–åå¸ƒå±€çš„å›¾ç‰‡ç”Ÿæˆ"""
    
    try:
        from image_generator import ImageGenerator
        
        # åˆ›å»ºæµ‹è¯•ç”¨çš„è®ºæ–‡æ•°æ® - å¤šä¸ªä½œè€…æµ‹è¯•
        test_paper = {
            'arxiv_id': '2507.12345',
            'title': 'Scaling Laws for Neural Language Models: A Comprehensive Analysis of Training Dynamics and Performance',
            'abstract': 'This paper investigates the scaling behavior of neural language models as we increase model size, dataset size, and computational resources. We propose unified scaling laws that predict model performance across these dimensions and demonstrate their effectiveness on various benchmarks. Our findings provide crucial insights for optimal resource allocation in training large-scale language models.',
            'authors': ['Tom Brown', 'Benjamin Mann', 'Nick Ryder', 'Melanie Subbiah', 'Jared Kaplan', 'Prafulla Dhariwal', 'Arvind Neelakantan'],
            'published_date': datetime(2025, 1, 22),
            'categories': ['cs.CL', 'cs.AI', 'cs.LG'],
            'keywords': ['scaling laws', 'neural networks', 'language models', 'training dynamics'],
            'arxiv_url': 'https://arxiv.org/abs/2507.12345',
            'pdf_url': 'https://arxiv.org/pdf/2507.12345.pdf'
        }
        
        # é•¿ä¸€ç‚¹çš„AIåˆ†ææ–‡æœ¬ï¼Œæµ‹è¯•æ¢è¡Œæ•ˆæœ
        test_analysis = """**ç ”ç©¶é¢†åŸŸ**ï¼šæ·±åº¦å­¦ä¹ ä¸è®¡ç®—è¯­è¨€å­¦ï¼Œä¸“æ³¨äºå¤§è§„æ¨¡ç¥ç»è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè§„å¾‹å’Œæ€§èƒ½ä¼˜åŒ–ç ”ç©¶ã€‚

**æ ¸å¿ƒè´¡çŒ®**ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æå‡ºäº†ç»Ÿä¸€çš„ç¥ç»è¯­è¨€æ¨¡å‹ç¼©æ”¾å®šå¾‹ï¼Œèƒ½å¤Ÿå‡†ç¡®é¢„æµ‹æ¨¡å‹åœ¨ä¸åŒè§„æ¨¡ã€æ•°æ®é›†å¤§å°å’Œè®¡ç®—èµ„æºé…ç½®ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼Œä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒæä¾›äº†ç†è®ºåŸºç¡€ã€‚

**æŠ€æœ¯æ–¹æ³•**ï¼šé€šè¿‡å¯¹æ•°ç™¾ä¸ªä¸åŒè§„æ¨¡çš„è¯­è¨€æ¨¡å‹è¿›è¡Œå®éªŒåˆ†æï¼Œå»ºç«‹äº†å‚æ•°æ•°é‡ã€è®­ç»ƒæ•°æ®è§„æ¨¡ã€è®¡ç®—é¢„ç®—ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´çš„æ•°å­¦å…³ç³»ï¼Œå¹¶æå‡ºäº†æœ€ä¼˜èµ„æºåˆ†é…ç­–ç•¥å’Œè®­ç»ƒè¶…å‚æ•°é€‰æ‹©æ–¹æ³•ã€‚

**å®éªŒç»“æœ**ï¼šåœ¨å¤šä¸ªæ ‡å‡†è¯„æµ‹åŸºå‡†ä¸ŠéªŒè¯äº†ç¼©æ”¾å®šå¾‹çš„å‡†ç¡®æ€§ï¼Œé¢„æµ‹è¯¯å·®æ§åˆ¶åœ¨5%ä»¥å†…ï¼ŒåŒæ—¶å‘ç°äº†è®­ç»ƒæ•ˆç‡çš„ä¸´ç•Œç‚¹å’Œæœ€ä¼˜é…ç½®å‚æ•°ï¼Œæ˜¾è‘—æå‡äº†å¤§æ¨¡å‹è®­ç»ƒçš„æˆæœ¬æ•ˆç›Šæ¯”ã€‚

**æ„ä¹‰ä»·å€¼**ï¼šä¸ºäººå·¥æ™ºèƒ½é¢†åŸŸçš„å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæä¾›äº†é‡è¦çš„ç†è®ºæŒ‡å¯¼å’Œå®è·µä¾æ®ï¼Œæœ‰åŠ©äºé™ä½è®¡ç®—æˆæœ¬ã€æé«˜è®­ç»ƒæ•ˆç‡ï¼Œæ¨åŠ¨äº†è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•å’Œäº§ä¸šåŒ–åº”ç”¨ã€‚"""
        
        print("=== æµ‹è¯•ä¼˜åŒ–åçš„å¸ƒå±€ ===")
        image_generator = ImageGenerator()
        
        print("ä¼˜åŒ–åé…ç½®:")
        print(f"- ç”»å¸ƒå°ºå¯¸: {image_generator.width} x {image_generator.height}")
        print(f"- å·¦æ å®½åº¦: {image_generator.left_column_width}px (ç¼©å°)")
        print(f"- å³æ å®½åº¦: {image_generator.right_column_width}px (å¢å¤§)")
        print(f"- è¾¹è·: {image_generator.margin}px")
        
        # æŸ¥æ‰¾æˆªå›¾æ–‡ä»¶
        screenshot_path = None
        screenshot_dir = os.path.join(image_generator.output_dir, '../screenshots')
        if os.path.exists(screenshot_dir):
            for file in os.listdir(screenshot_dir):
                if file.endswith('.png'):
                    screenshot_path = os.path.join(screenshot_dir, file)
                    print(f"æ‰¾åˆ°æµ‹è¯•æˆªå›¾: {screenshot_path}")
                    break
        
        if not screenshot_path:
            print("âš ï¸  æœªæ‰¾åˆ°æˆªå›¾æ–‡ä»¶ï¼Œå°†æµ‹è¯•æ— æˆªå›¾ç‰ˆæœ¬")
        
        print("\nå¼€å§‹ç”Ÿæˆä¼˜åŒ–åçš„å›¾ç‰‡...")
        
        # ç”Ÿæˆä¼˜åŒ–å¸ƒå±€å›¾ç‰‡
        image_path = image_generator.generate_paper_image(test_paper, test_analysis, screenshot_path)
        
        if image_path and os.path.exists(image_path):
            file_size = os.path.getsize(image_path)
            print(f"âœ… æˆåŠŸç”Ÿæˆä¼˜åŒ–åçš„å›¾ç‰‡!")
            print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {image_path}")
            print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size / 1024:.1f} KB")
            
            # æ˜¾ç¤ºç”Ÿæˆä¿¡æ¯
            from PIL import Image
            with Image.open(image_path) as img:
                print(f"ğŸ–¼ï¸  å›¾ç‰‡å°ºå¯¸: {img.width} x {img.height}")
                print(f"ğŸ¨ æ¨¡å¼: {img.mode}")
            
            print("\nğŸ“‹ ä¼˜åŒ–æ•ˆæœ:")
            print("  âœ“ ä¿¡æ¯æ æ›´çª„ (250px)ï¼Œä½œè€…é€è¡Œæ˜¾ç¤º")
            print("  âœ“ PDFé¢„è§ˆæ›´å¤§ (700px)ï¼Œæ›´æ¸…æ™°")
            print("  âœ“ AIåˆ†ææ–‡å­—ä¸å†é‡å ")
            print("  âœ“ æ•´ä½“å¸ƒå±€æ›´ç´§å‡‘")
            
            return True
        else:
            print("âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_optimized_layout()
    if success:
        print("\nğŸ‰ ä¼˜åŒ–å¸ƒå±€æµ‹è¯•å®Œæˆï¼")
        print("è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡ï¼ŒéªŒè¯ä»¥ä¸‹ä¼˜åŒ–æ•ˆæœ:")
        print("1. ä¿¡æ¯æ æ›´çª„ï¼Œä½œè€…ä¿¡æ¯æ¸…æ™°æ’åˆ—")
        print("2. PDFé¢„è§ˆåŒºåŸŸæ›´å¤§æ›´æ¸…æ™°") 
        print("3. AIåˆ†ææ–‡å­—æ­£ç¡®æ¢è¡Œï¼Œæ— é‡å ")
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")